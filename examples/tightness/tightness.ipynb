{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as rnd\n",
    "import jax.experimental.optimizers as opt\n",
    "import tqdm\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from rationality import dynamics as dyn, objectives as obj, distributions as dst,\\\n",
    "    controllers as ctl, simulate as sim, geometry as geom, util, inference as inf\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from typing import Optional, Callable\n",
    "from functools import partial"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "step_size = jnp.array(0.1)\n",
    "disturbance_iters = 100\n",
    "\n",
    "btl_scale = jnp.array(0.9)\n",
    "btl_iters = 1000\n",
    "\n",
    "r = 10.0\n",
    "\n",
    "betas = jnp.array([1.0])#jnp.exp(jnp.linspace(-1.0, 3.0, 20))\n",
    "prior_std = 1.0\n",
    "\n",
    "number_of_prior_samples = 100\n",
    "trials = 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def metric(x: float, x_hat: float) -> float:\n",
    "    return 0.5 * jnp.abs(x ** 2 - x_hat ** 2) + jnp.abs(x - x_hat)\n",
    "\n",
    "@partial(jax.jit, static_argnums=0)\n",
    "def btl(pred: Callable[[jnp.ndarray], bool], feasible_point: jnp.ndarray, new_point: jnp.ndarray, scaling: float):\n",
    "    @jax.jit\n",
    "    def btl_scanner(carry: float, temporal: None) -> tuple[float, tuple[float, jnp.ndarray]]:\n",
    "        direction = new_point - feasible_point\n",
    "        test_point = feasible_point + carry * direction\n",
    "\n",
    "        return (carry * scaling), (pred(test_point), test_point)\n",
    "\n",
    "    feas, points = jax.lax.scan(btl_scanner, 1.0, None, length=btl_iters)[1]\n",
    "\n",
    "    return jnp.append(feas, pred(feasible_point)), jnp.append(points, feasible_point)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def find_disturbance(x_hat: float, u: float, r: float, prior_samples: jnp.ndarray, beta: float) -> float:\n",
    "    @jax.jit\n",
    "    def predicate(test_point: jnp.ndarray) -> bool:\n",
    "        return metric(x_hat, x_hat - test_point) <= r\n",
    "\n",
    "    @jax.jit\n",
    "    def objective(d: jnp.ndarray) -> float:\n",
    "        prior_hamiltonian_values = jax.vmap(lambda prior: hamiltonian(x_hat - d, prior))(prior_samples)\n",
    "        logits = jax.vmap(lambda prior: log_prob(x_hat - d, prior, beta))(prior_samples)\n",
    "        unnormalized = jax.scipy.special.logsumexp(logits, b=prior_hamiltonian_values)\n",
    "\n",
    "        return unnormalized - jax.scipy.special.logsumexp(logits)\n",
    "\n",
    "    @jax.jit\n",
    "    def opt_scanner(current_disturbance: jnp.ndarray, _: None) -> tuple[jnp.ndarray, tuple[float, jnp.ndarray]]:\n",
    "        test_disturbance = current_disturbance + step_size * grad(current_disturbance)\n",
    "        feasible, disturbances = btl(predicate, current_disturbance, test_disturbance, btl_scale)\n",
    "        values = jax.vmap(objective, in_axes=-1)(disturbances)\n",
    "\n",
    "        best_idx = jnp.argmax(jnp.where(feasible, values, -1.0))\n",
    "\n",
    "\n",
    "        return disturbances[best_idx], (values[best_idx], disturbances[disturbance_iters])\n",
    "\n",
    "    grad = jax.jit(jax.grad(objective))\n",
    "\n",
    "    best_disturbance, opt_traj = jax.lax.scan(opt_scanner, jnp.array(0.0), None, length=disturbance_iters)\n",
    "\n",
    "    return best_disturbance\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def hamiltonian(x: float, u: float) -> float:\n",
    "    return jnp.array(0.5 * (x - u) ** 2, float)\n",
    "\n",
    "@jax.jit\n",
    "def lipschitz(u: float) -> float:\n",
    "    return jnp.maximum(jnp.abs(u), 0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def log_prob(x: float, u: float, beta: float) -> float:\n",
    "    return jax.scipy.stats.norm.logpdf(u, scale=prior_std) - beta * hamiltonian(x, u)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@jax.jit\n",
    "def conduct_trial(beta: float, key: jnp.ndarray, prior_samples: jnp.ndarray) -> tuple[float, float, float]:\n",
    "    key, sk1, sk2 = rnd.split(key, 3)\n",
    "\n",
    "    x_hat = rnd.normal(sk1)\n",
    "    u = inf.sir(lambda u: log_prob(x_hat, u, beta), prior_samples, sk2)\n",
    "    d = find_disturbance(x_hat, u, r, prior_samples, beta)\n",
    "    x = x_hat - d\n",
    "\n",
    "    return hamiltonian(x_hat, u), hamiltonian(x, u), metric(x, x_hat)\n",
    "\n",
    "key = rnd.PRNGKey(0)\n",
    "key, subkey = rnd.split(key)\n",
    "prior_samples = prior_std * rnd.normal(subkey, shape=(number_of_prior_samples,))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def helper(beta: float) -> tuple[float, float]:\n",
    "    fake, real, _ = jax.vmap(lambda subkey: conduct_trial(beta, subkey, prior_samples))(rnd.split(key, trials))\n",
    "\n",
    "    return fake.mean(), real.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fakes, reals = jax.vmap(helper)(betas)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(betas, fakes, label='Fully Observable')\n",
    "plt.plot(betas, reals, label='Worst Case')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}